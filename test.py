"""
Comprehensive Test Suite for LinkedIn Blog AI Assistant API

This test file covers all endpoints with real file uploads (PPT, PDF, Code)
Run with: pytest test_api_comprehensive.py -v

Prerequisites:
1. API server running on localhost:8000
2. Test files: sample.pdf, sample.pptx, sample.py in tests/fixtures/
3. Environment variables set (GROQ_API_KEY, GOOGLE_API_KEY, etc.)
"""

import pytest
import requests
import json
import time
import os
from pathlib import Path
from typing import Dict, Any, List
import tempfile

# Test Configuration
BASE_URL = "http://localhost:8000"
TEST_FILES_DIR = Path("tests/fixtures")

class TestAPIEndpoints:
    """Comprehensive test suite for all API endpoints"""
    
    @classmethod
    def setup_class(cls):
        """Setup test environment and create test files if needed"""
        cls.session_id = None
        cls.test_results = {}
        
        # Ensure test files directory exists
        TEST_FILES_DIR.mkdir(parents=True, exist_ok=True)
        
        # Create test files if they don't exist
        cls.create_test_files()
        
        # Verify API is running
        try:
            response = requests.get(f"{BASE_URL}/health")
            assert response.status_code == 200
            print("âœ… API server is running")
        except Exception as e:
            pytest.fail(f"âŒ API server not accessible: {e}")
    
    @classmethod
    def create_test_files(cls):
        """Create sample test files for testing"""
        
        # Create sample Python code
        python_file = TEST_FILES_DIR / "sample.py"
        if not python_file.exists():
            python_code = '''
"""
Machine Learning Data Processor
A comprehensive tool for processing and analyzing machine learning datasets
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt

class MLDataProcessor:
    """Advanced machine learning data processing pipeline"""
    
    def __init__(self, data_path: str):
        self.data_path = data_path
        self.data = None
        self.scaler = StandardScaler()
        self.model = RandomForestClassifier(n_estimators=100, random_state=42)
    
    def load_data(self):
        """Load and initial data validation"""
        try:
            self.data = pd.read_csv(self.data_path)
            print(f"Data loaded successfully: {self.data.shape}")
            return True
        except Exception as e:
            print(f"Error loading data: {e}")
            return False
    
    def preprocess_data(self, target_column: str):
        """Advanced preprocessing pipeline"""
        if self.data is None:
            raise ValueError("Data not loaded")
        
        # Handle missing values
        self.data = self.data.dropna()
        
        # Feature engineering
        numeric_columns = self.data.select_dtypes(include=[np.number]).columns
        categorical_columns = self.data.select_dtypes(include=['object']).columns
        
        # Scale numeric features
        X = self.data.drop(columns=[target_column])
        y = self.data[target_column]
        
        # Train-test split
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        return X_train, X_test, y_train, y_test
    
    def train_model(self, X_train, y_train):
        """Train the machine learning model"""
        X_train_scaled = self.scaler.fit_transform(X_train)
        self.model.fit(X_train_scaled, y_train)
        
        # Feature importance analysis
        feature_importance = pd.DataFrame({
            'feature': X_train.columns,
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        return feature_importance
    
    def evaluate_model(self, X_test, y_test):
        """Comprehensive model evaluation"""
        X_test_scaled = self.scaler.transform(X_test)
        predictions = self.model.predict(X_test_scaled)
        accuracy = self.model.score(X_test_scaled, y_test)
        
        print(f"Model accuracy: {accuracy:.4f}")
        return accuracy, predictions

def analyze_dataset_trends(data: pd.DataFrame) -> Dict[str, Any]:
    """Advanced statistical analysis of dataset trends"""
    
    analysis = {
        'shape': data.shape,
        'missing_values': data.isnull().sum().to_dict(),
        'numeric_stats': data.describe().to_dict(),
        'correlations': data.corr().to_dict() if len(data.select_dtypes(include=[np.number]).columns) > 1 else {},
        'data_types': data.dtypes.to_dict()
    }
    
    return analysis

if __name__ == "__main__":
    # Example usage
    processor = MLDataProcessor("dataset.csv")
    if processor.load_data():
        X_train, X_test, y_train, y_test = processor.preprocess_data("target")
        feature_importance = processor.train_model(X_train, y_train)
        accuracy, predictions = processor.evaluate_model(X_test, y_test)
        
        print("Top 5 Important Features:")
        print(feature_importance.head())
'''
            with open(python_file, 'w', encoding='utf-8') as f:
                f.write(python_code)
            print(f"âœ… Created test Python file: {python_file}")
        
        # Create sample text content for PDF simulation
        text_file = TEST_FILES_DIR / "sample.txt"
        if not text_file.exists():
            text_content = '''
The Future of Artificial Intelligence in Business Operations

Executive Summary
Artificial Intelligence (AI) is revolutionizing business operations across industries, from automating routine tasks to enabling sophisticated predictive analytics. This comprehensive analysis explores the current state and future potential of AI in business.

Key Findings
1. Automation Impact: AI automation is reducing operational costs by 20-30% in early adopter companies
2. Decision Making: Predictive analytics powered by AI improves decision accuracy by 40%
3. Customer Experience: AI-driven personalization increases customer satisfaction by 35%
4. Workforce Evolution: 60% of jobs will be augmented (not replaced) by AI within the next 5 years

Industry Applications

Healthcare
- Diagnostic assistance with 95% accuracy rates
- Drug discovery acceleration (reducing time by 50%)
- Personalized treatment recommendations
- Automated administrative tasks

Manufacturing
- Predictive maintenance reducing downtime by 25%
- Quality control with computer vision
- Supply chain optimization
- Real-time production adjustments

Financial Services
- Fraud detection with 99% accuracy
- Algorithmic trading and risk assessment
- Customer service chatbots
- Regulatory compliance automation

Implementation Strategies
1. Start Small: Begin with pilot projects in non-critical areas
2. Data Quality: Ensure high-quality, clean data for training
3. Change Management: Prepare workforce for AI integration
4. Ethical Considerations: Implement responsible AI practices
5. Continuous Learning: Establish feedback loops for improvement

Challenges and Solutions
- Data Privacy: Implement robust security measures and comply with regulations
- Skill Gaps: Invest in employee training and hire AI specialists
- Integration Complexity: Use phased implementation approaches
- Cost Considerations: Calculate ROI and start with high-impact areas

Future Outlook
The next decade will see AI becoming ubiquitous in business operations. Organizations that embrace AI strategically will gain significant competitive advantages. Key trends include:
- Edge AI for real-time processing
- Explainable AI for better decision transparency
- AI-human collaboration models
- Industry-specific AI solutions

Recommendations
1. Develop an AI strategy aligned with business objectives
2. Invest in data infrastructure and governance
3. Foster a culture of innovation and continuous learning
4. Partner with AI technology providers
5. Monitor emerging AI trends and technologies

Conclusion
AI represents a transformative opportunity for businesses willing to adapt and innovate. Success requires strategic planning, proper implementation, and a commitment to ethical AI practices.
'''
            with open(text_file, 'w', encoding='utf-8') as f:
                f.write(text_content)
            print(f"âœ… Created test text file: {text_file}")
    
    # HEALTH CHECK TESTS
    def test_01_health_check(self):
        """Test API health endpoint"""
        response = requests.get(f"{BASE_URL}/health")
        assert response.status_code == 200
        
        data = response.json()
        assert data["status"] == "healthy"
        assert "version" in data
        
        self.test_results["health_check"] = "âœ… PASSED"
        print("âœ… Health check passed")
    
    def test_02_root_endpoint(self):
        """Test root API information endpoint"""
        response = requests.get(f"{BASE_URL}/")
        assert response.status_code == 200
        
        data = response.json()
        assert "message" in data
        assert "endpoints" in data
        assert "features" in data
        
        self.test_results["root_endpoint"] = "âœ… PASSED"
        print("âœ… Root endpoint passed")
    
    # FILE INGESTION TESTS
    def test_03_ingest_python_file(self):
        """Test ingesting Python code file"""
        python_file = TEST_FILES_DIR / "sample.py"
        
        with open(python_file, 'rb') as f:
            files = {'file': ('sample.py', f, 'text/x-python')}
            response = requests.post(f"{BASE_URL}/api/ingest", files=files)
        
        assert response.status_code == 200
        data = response.json()
        
        assert data["success"] == True
        assert data["content_type"] == "code"
        assert "ai_analysis" in data
        assert len(data["key_insights"]) > 0
        assert "extracted_content" in data
        
        # Verify code-specific extraction
        extracted = data["extracted_content"]
        assert extracted["content_type"] == "code"
        assert "structured_data" in extracted
        
        self.test_results["ingest_python"] = "âœ… PASSED"
        print("âœ… Python file ingestion passed")
    
    def test_04_ingest_text_file(self):
        """Test ingesting text file (simulating PDF content)"""
        text_file = TEST_FILES_DIR / "sample.txt"
        
        with open(text_file, 'rb') as f:
            files = {'file': ('sample.txt', f, 'text/plain')}
            response = requests.post(f"{BASE_URL}/api/ingest", files=files)
        
        assert response.status_code == 200
        data = response.json()
        
        assert data["success"] == True
        assert data["content_type"] == "text"
        assert "ai_analysis" in data
        assert len(data["key_insights"]) > 0
        
        self.test_results["ingest_text"] = "âœ… PASSED"
        print("âœ… Text file ingestion passed")
    
    # BLOG GENERATION TESTS
    def test_05_generate_blog_from_text(self):
        """Test blog generation from text input"""
        blog_request = {
            "text": "Artificial Intelligence is transforming healthcare through predictive analytics, diagnostic assistance, and personalized treatment recommendations. Machine learning algorithms can analyze medical images with 95% accuracy, helping doctors detect diseases earlier. AI-powered drug discovery is reducing development time by 50%, potentially saving millions of lives.",
            "target_audience": "Healthcare professionals and technology leaders",
            "tone": "Professional and informative",
            "max_iterations": 2
        }
        
        response = requests.post(f"{BASE_URL}/api/generate-blog", json=blog_request)
        assert response.status_code == 200
        
        data = response.json()
        assert data["success"] == True
        assert "blog_post" in data
        assert data["iterations"] >= 1
        assert data["quality_score"] is not None
        
        # Verify blog structure
        blog_post = data["blog_post"]
        assert "title" in blog_post
        assert "hook" in blog_post
        assert "content" in blog_post
        assert "call_to_action" in blog_post
        assert "hashtags" in blog_post
        assert len(blog_post["hashtags"]) >= 3
        
        self.test_results["generate_blog_text"] = "âœ… PASSED"
        print("âœ… Blog generation from text passed")
    
    def test_06_generate_blog_from_file(self):
        """Test blog generation from uploaded file"""
        python_file = TEST_FILES_DIR / "sample.py"
        
        with open(python_file, 'rb') as f:
            files = {'file': ('sample.py', f, 'text/x-python')}
            data = {
                'target_audience': 'Data scientists and ML engineers',
                'tone': 'Technical but accessible',
                'max_iterations': 2
            }
            response = requests.post(f"{BASE_URL}/api/generate-blog-from-file", files=files, data=data)
        
        assert response.status_code == 200
        response_data = response.json()
        
        assert response_data["success"] == True
        assert "blog_post" in response_data
        assert response_data["quality_score"] is not None
        
        # Verify integration worked
        blog_post = response_data["blog_post"]
        assert "source_file" in blog_post
        assert "ingestion_analysis" in blog_post
        assert blog_post["source_file"] == "sample.py"
        
        self.test_results["generate_blog_file"] = "âœ… PASSED"
        print("âœ… Blog generation from file passed")
    
    # CHATBOT TESTS
    def test_07_start_chat_session(self):
        """Test starting a new chat session"""
        response = requests.post(f"{BASE_URL}/api/chat/start")
        assert response.status_code == 200
        
        data = response.json()
        assert "session_id" in data
        assert "current_stage" in data
        assert data["message_count"] == 0
        
        # Store session ID for subsequent tests
        self.__class__.session_id = data["session_id"]
        
        self.test_results["chat_start"] = "âœ… PASSED"
        print(f"âœ… Chat session started: {self.session_id}")
    
    def test_08_send_chat_message(self):
        """Test sending messages to chatbot"""
        if not self.session_id:
            pytest.skip("No active session")
        
        # Test initial greeting
        message_request = {
            "message": "Hi! I want to create a LinkedIn post about machine learning best practices.",
            "session_id": self.session_id
        }
        
        response = requests.post(f"{BASE_URL}/api/chat/message", json=message_request)
        assert response.status_code == 200
        
        data = response.json()
        assert data["success"] == True
        assert "response" in data
        assert data["session_id"] == self.session_id
        assert "current_stage" in data
        
        self.test_results["chat_message"] = "âœ… PASSED"
        print("âœ… Chat message sending passed")
    
    def test_09_chat_with_file_upload(self):
        """Test chatbot with file upload simulation"""
        if not self.session_id:
            pytest.skip("No active session")
        
        # Simulate file upload conversation
        message_request = {
            "message": "I have a Python file with ML code that I'd like to turn into a blog post. Please process the sample.py file in our test directory.",
            "session_id": self.session_id
        }
        
        response = requests.post(f"{BASE_URL}/api/chat/message", json=message_request)
        assert response.status_code == 200
        
        data = response.json()
        assert data["success"] == True
        assert len(data["response"]) > 0
        
        self.test_results["chat_file_upload"] = "âœ… PASSED"
        print("âœ… Chat with file upload passed")
    
    def test_10_submit_feedback(self):
        """Test submitting feedback on blog draft"""
        if not self.session_id:
            pytest.skip("No active session")
        
        feedback_request = {
            "session_id": self.session_id,
            "feedback": "Make the post more engaging and add some statistics about ML adoption in industry",
            "feedback_type": "content"
        }
        
        response = requests.post(f"{BASE_URL}/api/chat/feedback", json=feedback_request)
        assert response.status_code == 200
        
        data = response.json()
        assert data["success"] == True
        assert "response" in data
        
        self.test_results["chat_feedback"] = "âœ… PASSED"
        print("âœ… Feedback submission passed")
    
    def test_11_approve_blog_draft(self):
        """Test approving blog draft"""
        if not self.session_id:
            pytest.skip("No active session")
        
        approval_request = {
            "session_id": self.session_id,
            "approved": True,
            "final_notes": "Looks great! Ready to publish."
        }
        
        response = requests.post(f"{BASE_URL}/api/chat/approve", json=approval_request)
        assert response.status_code == 200
        
        data = response.json()
        assert data["success"] == True
        
        self.test_results["chat_approve"] = "âœ… PASSED"
        print("âœ… Blog approval passed")
    
    def test_12_get_chat_history(self):
        """Test retrieving chat history"""
        if not self.session_id:
            pytest.skip("No active session")
        
        response = requests.get(f"{BASE_URL}/api/chat/history/{self.session_id}")
        assert response.status_code == 200
        
        data = response.json()
        assert "session_id" in data
        assert "messages" in data
        assert len(data["messages"]) > 0
        
        self.test_results["chat_history"] = "âœ… PASSED"
        print("âœ… Chat history retrieval passed")
    
    def test_13_list_chat_sessions(self):
        """Test listing all chat sessions"""
        response = requests.get(f"{BASE_URL}/api/chat/sessions")
        assert response.status_code == 200
        
        data = response.json()
        assert "sessions" in data
        assert "total_sessions" in data
        assert data["total_sessions"] >= 1
        
        self.test_results["chat_sessions_list"] = "âœ… PASSED"
        print("âœ… Chat sessions listing passed")
    
    # MULTI-FILE AGGREGATION TESTS
    def test_14_multi_file_aggregation_synthesis(self):
        """Test multi-file aggregation with synthesis strategy"""
        python_file = TEST_FILES_DIR / "sample.py"
        text_file = TEST_FILES_DIR / "sample.txt"
        
        files = [
            ('files', ('sample.py', open(python_file, 'rb'), 'text/x-python')),
            ('files', ('sample.txt', open(text_file, 'rb'), 'text/plain'))
        ]
        
        data = {
            'aggregation_strategy': 'synthesis',
            'target_audience': 'Technology professionals',
            'tone': 'Professional and engaging',
            'max_iterations': 2
        }
        
        try:
            response = requests.post(f"{BASE_URL}/api/aggregate", files=files, data=data)
            
            if response.status_code == 200:
                response_data = response.json()
                assert response_data["success"] == True
                assert "blog_post" in response_data
                assert "aggregation_strategy" in response_data["blog_post"]
                assert response_data["blog_post"]["aggregation_strategy"] == "synthesis"
                assert "source_count" in response_data["blog_post"]
                assert response_data["blog_post"]["source_count"] == 2
                
                self.test_results["multi_file_synthesis"] = "âœ… PASSED"
                print("âœ… Multi-file synthesis aggregation passed")
            else:
                self.test_results["multi_file_synthesis"] = "âŒ FAILED"
                print(f"âŒ Multi-file synthesis failed: {response.status_code}")
                
        except Exception as e:
            self.test_results["multi_file_synthesis"] = "âŒ ERROR"
            print(f"âŒ Multi-file synthesis error: {e}")
        finally:
            # Close files
            for _, file_tuple in files:
                file_tuple[1].close()
    
    def test_15_multi_file_aggregation_comparison(self):
        """Test multi-file aggregation with comparison strategy"""
        python_file = TEST_FILES_DIR / "sample.py"
        text_file = TEST_FILES_DIR / "sample.txt"
        
        files = [
            ('files', ('sample.py', open(python_file, 'rb'), 'text/x-python')),
            ('files', ('sample.txt', open(text_file, 'rb'), 'text/plain'))
        ]
        
        data = {
            'aggregation_strategy': 'comparison',
            'target_audience': 'Technology professionals',
            'tone': 'Professional and engaging',
            'max_iterations': 2
        }
        
        try:
            response = requests.post(f"{BASE_URL}/api/aggregate", files=files, data=data)
            
            if response.status_code == 200:
                response_data = response.json()
                assert response_data["success"] == True
                assert response_data["blog_post"]["aggregation_strategy"] == "comparison"
                
                self.test_results["multi_file_comparison"] = "âœ… PASSED"
                print("âœ… Multi-file comparison aggregation passed")
            else:
                self.test_results["multi_file_comparison"] = "âŒ FAILED"
                print(f"âŒ Multi-file comparison failed: {response.status_code}")
                
        except Exception as e:
            self.test_results["multi_file_comparison"] = "âŒ ERROR"
            print(f"âŒ Multi-file comparison error: {e}")
        finally:
            # Close files
            for _, file_tuple in files:
                file_tuple[1].close()
    
    def test_16_multi_file_aggregation_validation(self):
        """Test multi-file aggregation validation (too few files, too many files)"""
        
        # Test with only 1 file (should fail)
        python_file = TEST_FILES_DIR / "sample.py"
        with open(python_file, 'rb') as f:
            files = [('files', ('sample.py', f, 'text/x-python'))]
            data = {'aggregation_strategy': 'synthesis'}
            response = requests.post(f"{BASE_URL}/api/aggregate", files=files, data=data)
        
        assert response.status_code == 400
        assert "At least 2 files" in response.json()["detail"]
        
        # Test with invalid strategy
        python_file = TEST_FILES_DIR / "sample.py"
        text_file = TEST_FILES_DIR / "sample.txt"
        
        files = [
            ('files', ('sample.py', open(python_file, 'rb'), 'text/x-python')),
            ('files', ('sample.txt', open(text_file, 'rb'), 'text/plain'))
        ]
        
        data = {'aggregation_strategy': 'invalid_strategy'}
        
        try:
            response = requests.post(f"{BASE_URL}/api/aggregate", files=files, data=data)
            assert response.status_code == 400
            assert "Invalid aggregation strategy" in response.json()["detail"]
            
            self.test_results["multi_file_validation"] = "âœ… PASSED"
            print("âœ… Multi-file validation tests passed")
        except Exception as e:
            self.test_results["multi_file_validation"] = "âŒ ERROR"
            print(f"âŒ Multi-file validation error: {e}")
        finally:
            # Close files
            for _, file_tuple in files:
                file_tuple[1].close()
    
    # ERROR HANDLING TESTS
    def test_17_invalid_file_upload(self):
        """Test error handling for invalid file uploads"""
        # Create a temporary invalid file
        with tempfile.NamedTemporaryFile(suffix='.xyz', delete=False) as tmp_file:
            tmp_file.write(b"Invalid file content")
            tmp_file.flush()
            
            with open(tmp_file.name, 'rb') as f:
                files = {'file': ('invalid.xyz', f, 'application/octet-stream')}
                response = requests.post(f"{BASE_URL}/api/ingest", files=files)
        
        # Clean up temp file
        os.unlink(tmp_file.name)
        
        # Should handle gracefully
        assert response.status_code in [400, 500]  # Expected error codes
        
        self.test_results["error_handling"] = "âœ… PASSED"
        print("âœ… Error handling for invalid files passed")
    
    def test_18_invalid_chat_session(self):
        """Test error handling for invalid chat session"""
        message_request = {
            "message": "Test message",
            "session_id": "invalid_session_id"
        }
        
        response = requests.post(f"{BASE_URL}/api/chat/message", json=message_request)
        assert response.status_code == 404  # Session not found
        
        self.test_results["invalid_session_handling"] = "âœ… PASSED"
        print("âœ… Invalid session error handling passed")
    
    # PERFORMANCE TESTS
    def test_19_concurrent_requests(self):
        """Test handling of concurrent requests"""
        import concurrent.futures
        import threading
        
        def make_health_request():
            return requests.get(f"{BASE_URL}/health")
        
        # Test 5 concurrent health checks
        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
            futures = [executor.submit(make_health_request) for _ in range(5)]
            responses = [future.result() for future in concurrent.futures.as_completed(futures)]
        
        # All should succeed
        for response in responses:
            assert response.status_code == 200
        
        self.test_results["concurrent_requests"] = "âœ… PASSED"
        print("âœ… Concurrent requests handling passed")
    
    # ADDITIONAL FILE TYPE TESTS
    def test_20_test_different_file_types(self):
        """Test ingestion with different file types"""
        
        # Test with a larger text file (simulating PDF content)
        large_text_file = TEST_FILES_DIR / "large_sample.txt"
        if not large_text_file.exists():
            large_content = "AI and Machine Learning: A Comprehensive Guide\n\n" * 50
            with open(large_text_file, 'w', encoding='utf-8') as f:
                f.write(large_content)
        
        with open(large_text_file, 'rb') as f:
            files = {'file': ('large_sample.txt', f, 'text/plain')}
            response = requests.post(f"{BASE_URL}/api/ingest", files=files)
        
        assert response.status_code == 200
        data = response.json()
        assert data["success"] == True
        assert len(data["key_insights"]) > 0
        
        self.test_results["different_file_types"] = "âœ… PASSED"
        print("âœ… Different file types test passed")
    
    def test_21_test_blog_generation_edge_cases(self):
        """Test blog generation with edge cases"""
        
        # Test with very short text
        short_request = {
            "text": "AI is cool.",
            "target_audience": "General",
            "tone": "Casual",
            "max_iterations": 1
        }
        
        response = requests.post(f"{BASE_URL}/api/generate-blog", json=short_request)
        assert response.status_code == 200
        data = response.json()
        assert data["success"] == True
        
        # Test with very long text
        long_text = "Artificial Intelligence and Machine Learning: A Comprehensive Analysis. " * 100
        long_request = {
            "text": long_text,
            "target_audience": "Technical professionals",
            "tone": "Professional",
            "max_iterations": 1
        }
        
        response = requests.post(f"{BASE_URL}/api/generate-blog", json=long_request)
        assert response.status_code == 200
        data = response.json()
        assert data["success"] == True
        
        self.test_results["blog_edge_cases"] = "âœ… PASSED"
        print("âœ… Blog generation edge cases passed")
    
    def test_22_test_api_documentation(self):
        """Test API documentation endpoint"""
        response = requests.get(f"{BASE_URL}/docs")
        assert response.status_code == 200
        assert "text/html" in response.headers.get("content-type", "")
        
        self.test_results["api_docs"] = "âœ… PASSED"
        print("âœ… API documentation endpoint passed")
    
    # CLEANUP AND SUMMARY
    def test_23_cleanup_session(self):
        """Test session cleanup"""
        if not self.session_id:
            pytest.skip("No active session")
        
        response = requests.delete(f"{BASE_URL}/api/chat/session/{self.session_id}")
        assert response.status_code == 200
        
        data = response.json()
        assert data["success"] == True
        
        self.test_results["session_cleanup"] = "âœ… PASSED"
        print("âœ… Session cleanup passed")
    
    def test_24_final_summary(self):
        """Print comprehensive test summary"""
        print("\n" + "="*70)
        print("ðŸŽ¯ COMPREHENSIVE API TEST RESULTS SUMMARY")
        print("="*70)
        
        passed_tests = []
        failed_tests = []
        skipped_tests = []
        
        for test_name, result in self.test_results.items():
            print(f"{result:<20} {test_name}")
            
            if "âœ…" in result:
                passed_tests.append(test_name)
            elif "âŒ" in result:
                failed_tests.append(test_name)
            else:
                skipped_tests.append(test_name)
        
        print("\n" + "="*70)
        print(f"ðŸ“Š SUMMARY:")
        print(f"   âœ… Passed: {len(passed_tests)}")
        print(f"   âŒ Failed: {len(failed_tests)}")
        print(f"   â­ï¸ Skipped/Not Implemented: {len(skipped_tests)}")
        print(f"   ðŸ“ˆ Success Rate: {len(passed_tests)/(len(passed_tests)+len(failed_tests))*100:.1f}%")
        
        if failed_tests:
            print(f"\nâŒ Failed Tests:")
            for test in failed_tests:
                print(f"   - {test}")
        
        if skipped_tests:
            print(f"\nâ­ï¸ Skipped/Not Implemented:")
            for test in skipped_tests:
                print(f"   - {test}")
        
        print("\n" + "="*70)
        print("ðŸŽ‰ API TESTING COMPLETE!")
        print("="*70)

# Additional Utility Functions for Manual Testing
class ManualTestRunner:
    """Helper class for running individual tests manually"""
    
    @staticmethod
    def test_specific_file(file_path: str):
        """Test a specific file upload"""
        with open(file_path, 'rb') as f:
            files = {'file': (Path(file_path).name, f, 'application/octet-stream')}
            response = requests.post(f"{BASE_URL}/api/ingest", files=files)
        
        print(f"Testing file: {file_path}")
        print(f"Status: {response.status_code}")
        
        if response.status_code == 200:
            data = response.json()
            print(f"Success: {data['success']}")
            print(f"Content Type: {data['content_type']}")
            print(f"Insights: {len(data['key_insights'])}")
        else:
            print(f"Error: {response.text}")
    
    @staticmethod
    def test_blog_generation_speed():
        """Test blog generation speed"""
        start_time = time.time()
        
        blog_request = {
            "text": "AI is transforming business operations through automation and predictive analytics.",
            "target_audience": "Business executives",
            "tone": "Professional",
            "max_iterations": 1
        }
        
        response = requests.post(f"{BASE_URL}/api/generate-blog", json=blog_request)
        end_time = time.time()
        
        print(f"Blog generation time: {end_time - start_time:.2f} seconds")
        print(f"Status: {response.status_code}")
        
        if response.status_code == 200:
            data = response.json()
            print(f"Quality Score: {data['quality_score']}")
            print(f"Iterations: {data['iterations']}")

if __name__ == "__main__":
    # Run specific tests manually
    print("Manual test runner - uncomment desired tests:")
    
    # ManualTestRunner.test_specific_file("tests/fixtures/sample.py")
    # ManualTestRunner.test_blog_generation_speed()
    
    print("Run full test suite with: pytest test_api_comprehensive.py -v")